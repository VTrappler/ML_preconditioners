{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2237141e-104e-4644-8fb0-eea3ebd6d306",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a864e351-6c18-4438-9724-618ca03b2260",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2459fed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9],\n",
       "        [10, 11, 12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diago = torch.arange(20).reshape(2, 10)\n",
    "diago"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b5457f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  1,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  2,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  3,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  4,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  5,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  6,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  7,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  8,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  9]],\n",
       "\n",
       "        [[10,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0, 11,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0, 12,  0,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, 13,  0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0, 14,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0, 15,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0, 16,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0, 17,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0, 18,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0,  0,  0,  0, 19]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.diag_embed(diago)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5cdb78e7-ce0e-47ad-8361-af898a012e4e",
   "metadata": {},
   "source": [
    "## Circular CNN 1D"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adf844e4-0a27-4952-aea2-0c8e1faf4974",
   "metadata": {},
   "source": [
    "Set easier weights and input vector for easy visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "970280a1-4c05-4d7e-bea6-8c00e5724b84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.,  9., 10.]]]) torch.Size([1, 1, 10])\n",
      "tensor([[[25., 30., 25., 30., 25., 30., 25., 30., 25., 30.]]],\n",
      "       grad_fn=<ConvolutionBackward0>) torch.Size([1, 1, 10])\n"
     ]
    }
   ],
   "source": [
    "n_in = 10\n",
    "kernel_size = 5\n",
    "dilation = 2\n",
    "padding_mode = \"circular\"\n",
    "conv_layer_simple = torch.nn.Conv1d(\n",
    "    1,\n",
    "    1,\n",
    "    kernel_size,\n",
    "    padding=(kernel_size // 2) * dilation,\n",
    "    dilation=dilation,\n",
    "    padding_mode=padding_mode,\n",
    "    bias=False,\n",
    ")\n",
    "# in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None\n",
    "conv_layer_simple.weight = torch.nn.Parameter(torch.ones_like(conv_layer_simple.weight))\n",
    "x = torch.rand(size=(1, 1, 10))\n",
    "for i in range(n_in):\n",
    "    x[:, :, i] = 1.0 * i + 1\n",
    "print(x, x.shape)\n",
    "print(conv_layer_simple(x), conv_layer_simple(x).shape)\n",
    "\n",
    "\n",
    "# conv_layer_simple = torch.nn.Conv1d(1, 1, kernel_size, padding=kernel_size//2, dilation=3, padding_mode=padding_mode, bias=False)\n",
    "# # in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros', device=None, dtype=None\n",
    "# # conv_layer_simple.weight = torch.nn.Parameter(torch.ones_like(conv_layer_simple.weight))\n",
    "# print(x)\n",
    "# print(conv_layer_simple(x))\n",
    "conv_layers_dilations = []\n",
    "for dilation in [1, 2, 4]:\n",
    "    conv_layers_dilations.append(\n",
    "        torch.nn.Conv1d(\n",
    "            1,\n",
    "            1,\n",
    "            kernel_size,\n",
    "            padding=(kernel_size // 2) * dilation,\n",
    "            dilation=dilation,\n",
    "            padding_mode=padding_mode,\n",
    "            bias=False,\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "class ParallelConv1DDilations(torch.nn.Module):\n",
    "    def __init__(self, n_in, dilation_list, kernel_size):\n",
    "        self.n_in = n_in\n",
    "        self.dilation_list = dilation_list\n",
    "        self.kernel_size = kernel_size\n",
    "        self.conv_layers_dilations = []\n",
    "        for dilation in self.dilation_list:\n",
    "            self.conv_layers_dilations.append(\n",
    "                torch.nn.Conv1d(\n",
    "                    1,\n",
    "                    1,\n",
    "                    self.kernel_size,\n",
    "                    padding=(self.kernel_size // 2) * dilation,\n",
    "                    dilation=dilation,\n",
    "                    padding_mode=padding_mode,\n",
    "                    bias=False,\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.concatenate(\n",
    "            [conv_layer.forward(x) for conv_layer in self.conv_layers_dilations], dim=1\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "542ed602",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.1120, -0.2639,  0.0031, -0.1549, -0.2375,  0.0671, -0.1858,\n",
       "           0.0051, -0.1655, -0.0495],\n",
       "         [ 0.0411,  0.1064, -0.0354,  0.3129,  0.0115,  0.0154,  0.0843,\n",
       "           0.0265,  0.1328, -0.2361],\n",
       "         [ 0.2629,  0.4463,  0.3205,  0.4201,  0.4206, -0.0125,  0.3739,\n",
       "           0.3169,  0.2941,  0.4365]],\n",
       "\n",
       "        [[ 0.1675, -0.2076, -0.0058, -0.1177, -0.0787, -0.0818, -0.0606,\n",
       "           0.1404, -0.2460, -0.0282],\n",
       "         [-0.0048,  0.1183, -0.0030,  0.1453,  0.0798,  0.1004, -0.1710,\n",
       "           0.0563,  0.2317, -0.2793],\n",
       "         [ 0.1675,  0.4078,  0.0153,  0.2796,  0.3675, -0.0599,  0.0906,\n",
       "           0.2171,  0.3069,  0.1626]]], grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parconv = ParallelConv1DDilations(10, [1, 2, 4], kernel_size=3)\n",
    "x = torch.rand((2, 1, 10))\n",
    "parconv.forward(x)\n",
    "# parconv.conv_layers_dilations[0](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f022c633",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_vec = torch.nn.Conv1d(1, 5, kernel_size, padding=kernel_size//2, padding_mode=padding_mode, bias=True)\n",
    "layers_vec = torch.nn.Sequential(conv_layer_vec, torch.nn.Conv1d(5, 5, kernel_size, padding=kernel_size//2, padding_mode=padding_mode, bias=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49783021",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_layer_val = torch.nn.Conv1d(1, 1, kernel_size, padding=kernel_size//2, padding_mode=padding_mode, bias=True)\n",
    "layers_val = torch.nn.Sequential(conv_layer_val, torch.nn.Flatten(), torch.nn.Linear(n_in, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071e3a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_conv1D(n_in, n_c, kernel_size):\n",
    "    padding_mode = 'circular'\n",
    "\n",
    "    layers_vec = torch.nn.Sequential(\n",
    "        torch.nn.Conv1d(\n",
    "            1, n_c, kernel_size, padding=kernel_size // 2, padding_mode=padding_mode\n",
    "        ),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv1d(\n",
    "            n_c, n_c, kernel_size, padding=kernel_size // 2, padding_mode=padding_mode\n",
    "        ),        \n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv1d(\n",
    "            n_c, n_c, kernel_size, padding=kernel_size // 2, padding_mode=padding_mode\n",
    "        )\n",
    "    )\n",
    "    return layers_vec\n",
    "\n",
    "def construct_conv1D_singularvalue(n_in, n_c, kernel_size):\n",
    "    padding_mode = 'circular'\n",
    "    layers_vec = torch.nn.Sequential(\n",
    "        torch.nn.Conv1d(\n",
    "            1, n_c, kernel_size, padding=kernel_size // 2, padding_mode=padding_mode\n",
    "        ),\n",
    "        torch.nn.LeakyReLU(),\n",
    "        torch.nn.Conv1d(\n",
    "            n_c, n_c, kernel_size, padding=kernel_size // 2, padding_mode=padding_mode\n",
    "        ),\n",
    "        torch.nn.AdaptiveAvgPool1d(1)\n",
    ")\n",
    "    return layers_vec\n",
    "\n",
    "class ConvLayersSVD(torch.nn.Module):\n",
    "    def __init__(self, state_dimension, n_latent, kernel_size) -> None:\n",
    "        super().__init__()\n",
    "        self.state_dimension = state_dimension\n",
    "        self.n_latent = n_latent\n",
    "        self.kernel_size = kernel_size\n",
    "        self.layers_vec = construct_conv1D(self.state_dimension, self.n_latent, kernel_size=self.kernel_size)\n",
    "        self.layers_sing = construct_conv1D_singularvalue(self.state_dimension, self.n_latent, kernel_size=self.kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.atleast_2d(x)\n",
    "        x = x.view(len(x), 1, -1)\n",
    "        n_batch = len(x)\n",
    "        vectors = torch.nn.functional.normalize(self.layers_vec(x), dim=-1)\n",
    "        # print(vectors.shape)\n",
    "        singvals = self.layers_sing(x)\n",
    "        # print(singvals.shape)\n",
    "        return torch.concat((vectors, singvals.view(n_batch, self.n_latent, 1)), -1).transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82861b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_batch = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6db008-9185-4088-9d9c-fd9f7ed2df26",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvlay = ConvLayersSVD(n_in, 5, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b412d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2980,  0.4329, -0.3129,  0.1985, -0.1530],\n",
       "         [ 0.2880,  0.0788, -0.2610,  0.3299, -0.3597],\n",
       "         [ 0.2960,  0.2517, -0.3093,  0.3250, -0.2888],\n",
       "         [ 0.3027,  0.2783, -0.2933,  0.2723, -0.2972],\n",
       "         [ 0.3030,  0.2961, -0.3143,  0.4179, -0.2969],\n",
       "         [ 0.3159,  0.3660, -0.2843,  0.1142, -0.2591],\n",
       "         [ 0.3317,  0.0852, -0.2947,  0.4397, -0.5066],\n",
       "         [ 0.3581,  0.4299, -0.3672,  0.1789, -0.2540],\n",
       "         [ 0.3374,  0.2407, -0.3371,  0.3176, -0.3805],\n",
       "         [ 0.3244,  0.4403, -0.3706,  0.3976, -0.2328],\n",
       "         [ 0.0846,  0.1798,  0.2533,  0.0216, -0.2732]],\n",
       "\n",
       "        [[ 0.3217,  0.3604, -0.3406,  0.1952, -0.2250],\n",
       "         [ 0.2971,  0.2094, -0.3225,  0.4123, -0.3136],\n",
       "         [ 0.2790,  0.3533, -0.3344,  0.2996, -0.1504],\n",
       "         [ 0.2641,  0.1481, -0.2412,  0.2960, -0.2601],\n",
       "         [ 0.2893,  0.1477, -0.2717,  0.3430, -0.3383],\n",
       "         [ 0.3152,  0.2503, -0.2926,  0.2367, -0.3360],\n",
       "         [ 0.3523,  0.2426, -0.3082,  0.3103, -0.4753],\n",
       "         [ 0.3653,  0.4964, -0.3828,  0.4102, -0.3220],\n",
       "         [ 0.3455,  0.5256, -0.3387,  0.1119, -0.1955],\n",
       "         [ 0.3173,  0.1160, -0.3071,  0.4046, -0.4069],\n",
       "         [ 0.0793,  0.1818,  0.2581,  0.0210, -0.2745]],\n",
       "\n",
       "        [[ 0.3287,  0.3885, -0.3548,  0.3458, -0.2376],\n",
       "         [ 0.2826,  0.3179, -0.3195,  0.2423, -0.1804],\n",
       "         [ 0.2641,  0.1168, -0.2590,  0.3899, -0.3033],\n",
       "         [ 0.2850,  0.2298, -0.2904,  0.2978, -0.2346],\n",
       "         [ 0.2737,  0.1828, -0.2769,  0.2973, -0.2810],\n",
       "         [ 0.2942,  0.1860, -0.2743,  0.3270, -0.3560],\n",
       "         [ 0.3250,  0.3243, -0.3140,  0.3540, -0.3437],\n",
       "         [ 0.3519,  0.3064, -0.3082,  0.1521, -0.3611],\n",
       "         [ 0.3645,  0.2404, -0.3492,  0.4164, -0.4989],\n",
       "         [ 0.3706,  0.5973, -0.3914,  0.2526, -0.2467],\n",
       "         [ 0.0826,  0.1756,  0.2549,  0.0209, -0.2788]]],\n",
       "       grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvlay(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a54c067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1358,  0.0990, -0.3278, -0.2547,  0.2109],\n",
      "         [-0.0716,  0.0615, -0.3629, -0.1930,  0.3808],\n",
      "         [-0.0047,  0.3467, -0.3492,  0.1315,  0.3603],\n",
      "         [ 0.3694,  0.3933, -0.2941,  0.3996,  0.3424],\n",
      "         [ 0.3567,  0.3802, -0.2952,  0.3840,  0.3458],\n",
      "         [ 0.3439,  0.3672, -0.2964,  0.3683,  0.3493],\n",
      "         [ 0.3312,  0.3541, -0.2975,  0.3527,  0.3527],\n",
      "         [ 0.2965,  0.3460, -0.3230,  0.3306,  0.3227],\n",
      "         [ 0.5737,  0.4267, -0.2949,  0.2376,  0.2588],\n",
      "         [ 0.2601, -0.0710, -0.3123, -0.3843,  0.1624]],\n",
      "\n",
      "        [[-0.1985, -0.1614, -0.3306, -0.5375,  0.1905],\n",
      "         [-0.3148, -0.3894, -0.3626, -0.4574,  0.4222],\n",
      "         [-0.1900,  0.2896, -0.3514, -0.2018,  0.3650],\n",
      "         [ 0.3226,  0.3429, -0.2973,  0.0481,  0.3927],\n",
      "         [ 0.3133,  0.3081, -0.2987,  0.0047,  0.3705],\n",
      "         [ 0.3039,  0.2733, -0.3001, -0.0386,  0.3483],\n",
      "         [ 0.2946,  0.2384, -0.3015, -0.0820,  0.3262],\n",
      "         [ 0.2616,  0.2316, -0.3149, -0.0938,  0.2911],\n",
      "         [ 0.6095,  0.2777, -0.2966, -0.2491,  0.1993],\n",
      "         [ 0.0643, -0.5135, -0.3000, -0.6162,  0.0924]],\n",
      "\n",
      "        [[-0.2952, -0.4313, -0.3327, -0.4627,  0.0026],\n",
      "         [-0.4968, -0.6101, -0.3661, -0.4002,  0.5392],\n",
      "         [-0.3117, -0.0483, -0.3505, -0.2897,  0.3595],\n",
      "         [ 0.2483, -0.0041, -0.2983, -0.1762,  0.4258],\n",
      "         [ 0.2382, -0.0305, -0.2996, -0.1960,  0.3705],\n",
      "         [ 0.2281, -0.0569, -0.3010, -0.2158,  0.3153],\n",
      "         [ 0.2179, -0.0833, -0.3023, -0.2357,  0.2601],\n",
      "         [ 0.1830, -0.0862, -0.3135, -0.2386,  0.1844],\n",
      "         [ 0.5623, -0.0607, -0.2981, -0.3152, -0.0443],\n",
      "         [-0.0355, -0.6459, -0.2909, -0.4625, -0.2418]]],\n",
      "       grad_fn=<DivBackward0>)\n",
      "torch.Size([3, 10, 5])\n"
     ]
    }
   ],
   "source": [
    "x = torch.linspace(0, n_in - 1, n_in * nbatch).reshape(nbatch, 1, n_in)\n",
    "lays = construct_conv1D(n_in, 5, 3)\n",
    "lays(x).transpose(1, 2).shape\n",
    "print(y := torch.nn.functional.normalize(lays(x).transpose(1, 2)))\n",
    "y.norm(dim=1), print(y.shape)\n",
    "cc=  construct_conv1D_singularvalue(n_in, 5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96159605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 5, 1])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc(x).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ff68ac-b02a-49f8-9860-4271d4e5920f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.shape=torch.Size([3, 1, 10]), y.shape=torch.Size([3, 10, 5])\n",
      "x.shape=torch.Size([3, 1, 10]), layers_vec(x).shape=torch.Size([3, 5, 10])\n",
      "x.shape=torch.Size([3, 1, 10]), layers_val(x).shape=torch.Size([3, 5])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5, 10]), torch.Size([3, 5]))"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{x.shape=}, {y.shape=}\")\n",
    "print(f\"{x.shape=}, {layers_vec(x).shape=}\")\n",
    "print(f\"{x.shape=}, {layers_val(x).shape=}\")\n",
    "y, z = layers_vec(x), layers_val(x)\n",
    "y.shape, z.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6086e5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 11, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcbbe15-0aa3-466b-8f53-8e8927cb083c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3c8ae6c9d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conv_matrix = torch.zeros((n_in, n_in))\n",
    "for i in range(n_in):\n",
    "    conv_matrix[i, i % n_in] = 1.0\n",
    "    for j in range(kernel_size):\n",
    "        conv_matrix[i, (i+j - kernel_size//2) % n_in] = 1.0\n",
    "plt.imshow(conv_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4106066d-fee8-4564-8193-a08392ad3655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(conv_matrix @ x.squeeze() == y).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff85d54d-6c7f-446b-a2fc-50bf182c1bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2., 3., 4., 5.]]])\n",
      "tensor([[[ 6.,  3.,  6.,  9., 12.,  9.]]], grad_fn=<SqueezeBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "305980e6-ec30-4708-81a7-79949f6f4a1e",
   "metadata": {},
   "source": [
    "## Self Attention Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f47308a-6da8-4f5c-af1a-ca5bdd7b716e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d917e8-b6c1-418b-85a2-65061317c5d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_layer = torch.nn.MultiheadAttention(embed_dim=embed_dim, num_heads=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8527d32f-b5b2-4e25-9631-d4765ecd7cd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
